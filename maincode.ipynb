{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV-2Kqu9WHhu"
      },
      "source": [
        "# Data Exploration and Scikit-Learn\n",
        "\n",
        "In this final Python lesson, we'll use everything we've learned so far and work with some real datasets. We'll also finally use the Scikit-Learn library (called `sklearn` in Python) to do some basic machine learning on some sample data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDFIigZ5VXSs"
      },
      "source": [
        "## Some important imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_4G-kOwVq4K"
      },
      "source": [
        "In Jupyter Notebooks, we can import the libraries we need once, and then use the libraries on all future code blocks without needing to re-import everything.\n",
        "\n",
        "Run the following code block:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KnWCWO8VawZ"
      },
      "source": [
        "%matplotlib inline\n",
        "import sklearn\n",
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o918trVrjUH"
      },
      "source": [
        "## Get that dataset!\n",
        "\n",
        "Before we can start to do machine learning, we need to have data to train our systems on. If you remember in the \"Introduction to Machine Learning\" lesson, datasets aren't always easy to come by, and many are privately collected and owned. Very often, if you want to work on a new machine learning application, you may have to figure out how to collect your own data.\n",
        "\n",
        "However, there are many great services that have open and free datasets that you can use, like [Kaggle](https://www.kaggle.com/). For this lesson, we'll use a dataset from Kaggle that contains Spotify information on the top songs of 2017."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siyKab1mtSSG"
      },
      "source": [
        "## Grabbing datasets from GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X6-63sysdM7"
      },
      "source": [
        "We've actually stored the dataset in a different website, called [GitHub](https://github.com/), so that we can easily grab the data for this lesson.\n",
        "\n",
        "Be sure to run each of the code blocks below. They're not written in Python -- they're written in a different language called Bash, which is typically used on the command line and can manipulate things like files on your computer.\n",
        "\n",
        "You don't have to worry about what each of these code blocks does, just that they help us pull data from GitHub so that we have access to it within this Notebook. (Almost like how we need to import libraries before we can start to use them.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhSPs8MUUyIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c5fa84-4676-45d6-df56-53bd354dc556"
      },
      "source": [
        "# The following is not a Python command, but a bash command\n",
        "# It looks at the files and folders in this current directory\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kMznGGHUzpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf190b2-f700-4b56-ac3f-90d20023072a"
      },
      "source": [
        "# This checks if the directory called \"random-data\" exists, and if so, remove it\n",
        "! if [ -d \"random-data\" ]; then rm -r random-data; fi\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj4x7BDiU1GW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c79e9b0-d7ea-4d76-ec27-dbe639f44bbf"
      },
      "source": [
        "# This creates a new directory based on a repo from my GitHub\n",
        "! git clone https://github.com/Devking/random-data.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'random-data'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Receiving objects: 100% (19/19), 102.20 KiB | 3.30 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmnLi3frU3rQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b83572d-af9f-49b9-b368-70647b0e9581"
      },
      "source": [
        "# This is for us to check that the directory was successfully downloaded\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random-data  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZbLoBYMVPFG"
      },
      "source": [
        "# Spotify's Top Songs of 2017\n",
        "\n",
        "Let's say that you were interested in music and wanted to create a machine learning system to suggest a new song for someone to listen to. How would we create this?\n",
        "\n",
        "Well first, we would need to have some data on what music people like. Once we have that data, we might start to think about the different qualities of a song, so you can recommend new songs based on similar qualities from songs a person has listened to.\n",
        "\n",
        "The Spotify Top Songs of 2017 dataset contains exactly that information, so let's see how we would start to use it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iJbHGkbue1H"
      },
      "source": [
        "## Working with Pandas\n",
        "\n",
        "Before we jump into machine learning, let's practice looking at datasets and exploring them. We'll use a library called `pandas` to help us do this.\n",
        "\n",
        "We've already imported `pandas` earlier in the Notebook, so we can use it in the following code blocks. If you did not run the first code block of this lesson, the following code will raise an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAgze1dMuqsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85d0844-e7b3-49ec-d031-0da00977dc57"
      },
      "source": [
        "# This is the file name of the Spotify dataset\n",
        "# It's a \"CSV\" file, which stands for \"comma-separated values file\"\n",
        "# Really, it's just a long text file with a lot of information separated by commas\n",
        "filename = \"random-data/spotify.csv\"\n",
        "\n",
        "# We will use a function built into pandas to read our csv data\n",
        "data = pandas.read_csv(filename)\n",
        "\n",
        "# Finally, we'll print the data to take a look at it\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0  acousticness  danceability  duration_ms  energy  \\\n",
            "0              0       0.01020         0.833       204600   0.434   \n",
            "1              1       0.19900         0.743       326933   0.359   \n",
            "2              2       0.03440         0.838       185707   0.412   \n",
            "3              3       0.60400         0.494       199413   0.338   \n",
            "4              4       0.18000         0.678       392893   0.561   \n",
            "...          ...           ...           ...          ...     ...   \n",
            "2012        2012       0.00106         0.584       274404   0.932   \n",
            "2013        2013       0.08770         0.894       182182   0.892   \n",
            "2014        2014       0.00857         0.637       207200   0.935   \n",
            "2015        2015       0.00164         0.557       185600   0.992   \n",
            "2016        2016       0.00281         0.446       204520   0.915   \n",
            "\n",
            "      instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
            "0             0.021900    2    0.1650    -8.795     1       0.4310  150.062   \n",
            "1             0.006110    1    0.1370   -10.401     1       0.0794  160.083   \n",
            "2             0.000234    2    0.1590    -7.148     1       0.2890   75.044   \n",
            "3             0.510000    5    0.0922   -15.236     1       0.0261   86.468   \n",
            "4             0.512000    5    0.4390   -11.648     0       0.0694  174.004   \n",
            "...                ...  ...       ...       ...   ...          ...      ...   \n",
            "2012          0.002690    1    0.1290    -3.501     1       0.3330   74.976   \n",
            "2013          0.001670    1    0.0528    -2.663     1       0.1310  110.041   \n",
            "2014          0.003990    0    0.2140    -2.467     1       0.1070  150.082   \n",
            "2015          0.677000    1    0.0913    -2.735     1       0.1330  150.011   \n",
            "2016          0.000039    9    0.2180    -6.221     1       0.1410  190.013   \n",
            "\n",
            "      time_signature  valence  target                            song_title  \\\n",
            "0                4.0    0.286       1                              Mask Off   \n",
            "1                4.0    0.588       1                               Redbone   \n",
            "2                4.0    0.173       1                          Xanny Family   \n",
            "3                4.0    0.230       1                        Master Of None   \n",
            "4                4.0    0.904       1                        Parallel Lines   \n",
            "...              ...      ...     ...                                   ...   \n",
            "2012             4.0    0.211       0   Like A Bitch - Kill The Noise Remix   \n",
            "2013             4.0    0.867       0                                 Candy   \n",
            "2014             4.0    0.470       0  Habit - Dack Janiels & Wenzday Remix   \n",
            "2015             4.0    0.623       0                         First Contact   \n",
            "2016             4.0    0.402       0                    I Wanna Get Better   \n",
            "\n",
            "                artist  \n",
            "0               Future  \n",
            "1     Childish Gambino  \n",
            "2               Future  \n",
            "3          Beach House  \n",
            "4          Junior Boys  \n",
            "...                ...  \n",
            "2012    Kill The Noise  \n",
            "2013    Dillon Francis  \n",
            "2014          Rain Man  \n",
            "2015        Twin Moons  \n",
            "2016         Bleachers  \n",
            "\n",
            "[2017 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u56pvsyqvyaa"
      },
      "source": [
        "The print-out of our data above looks... not too informative. This is mainly because there's a lot of data in our dataset that we're working with, and Jupyter Notebooks doesn't format it nicely for us when we directly print all of the data. Instead, we'll have to use some functions in `pandas` to explore the data ourselves.\n",
        "\n",
        "By the way, if you want to see the data in this dataset as a table, you can [click here to see it displayed in GitHub](https://github.com/Devking/random-data/blob/master/spotify.csv). We'll also write some code so that we can visualize our data in table form.\n",
        "\n",
        "There are 2017 rows in this dataset and 17 columns, where each row is a single song and (almost) each column is a **feature** of the song. In terms of dataset size, this is closer to the small side -- some datasets may have thousands or even millions of rows.\n",
        "\n",
        "## Exploring some features\n",
        "\n",
        "Recall that our data in datasets is described by a set of properties called features.\n",
        "\n",
        "For song data, some features you might expect are tempo, time signature, and name.\n",
        "\n",
        "Let's print all of the names of the songs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d05N6hixvUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdb12e3-2d8c-47a7-bf0f-9f4415919ce0"
      },
      "source": [
        "# Notice that we didn't just say \"name\"\n",
        "# Like with accessing values in dictionaries, the specific key value in this data set is \"song_title\"\n",
        "print(data[\"song_title\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                   Mask Off\n",
            "1                                    Redbone\n",
            "2                               Xanny Family\n",
            "3                             Master Of None\n",
            "4                             Parallel Lines\n",
            "                        ...                 \n",
            "2012     Like A Bitch - Kill The Noise Remix\n",
            "2013                                   Candy\n",
            "2014    Habit - Dack Janiels & Wenzday Remix\n",
            "2015                           First Contact\n",
            "2016                      I Wanna Get Better\n",
            "Name: song_title, Length: 2017, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZRM0CDEyL7k"
      },
      "source": [
        "The above code prints the song titles for all 2017 songs in our dataset. However, if we wanted to recommend a new song to someone, it probably wouldn't be enough to just recommend them based on song title. We'll want to make use of multiple features, and it may help us to visualize them to find patterns in the data.\n",
        "\n",
        "How do we know what all of the features in our dataset are? One way is to look directly at the CSV file, because these are usually the column headers that are on the first line of the file. (We could also look at the column headings in GitHub since it displays all of the data in a table nicely for us.) Since we're trying to work with our Python code as much as possible, let's see how we would do it in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqNtL7KdzMC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae71a20-e521-4b02-abfe-54b0df44a75b"
      },
      "source": [
        "filename = \"random-data/spotify.csv\"\n",
        "raw_data = pandas.read_csv(filename)\n",
        "\n",
        "# Get the values of the columns (the features) and print them out\n",
        "features = raw_data.columns.values\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unnamed: 0' 'acousticness' 'danceability' 'duration_ms' 'energy'\n",
            " 'instrumentalness' 'key' 'liveness' 'loudness' 'mode' 'speechiness'\n",
            " 'tempo' 'time_signature' 'valence' 'target' 'song_title' 'artist']\n"
          ]
        }
      ]
    },
